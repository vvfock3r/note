## ğŸ ä½¿ç”¨kubesprayéƒ¨ç½²

æ–‡æ¡£1ï¼š[https://kubernetes.io/zh-cn/docs/setup/production-environment/tools/kubespray/](https://kubernetes.io/zh-cn/docs/setup/production-environment/tools/kubespray/)

æ–‡æ¡£2ï¼š[https://github.com/kubernetes-sigs/kubespray](https://github.com/kubernetes-sigs/kubespray)

### å¿…è¯»è¯´æ˜

**ï¼ˆ1ï¼‰èŠ‚ç‚¹è§„åˆ’**

:::tip

æ ¹æ®ä»¥ä¸‹ä¿¡æ¯å®‰è£…æ“ä½œç³»ç»Ÿï¼Œå®‰è£…å®Œæˆåä¸éœ€è¦åšä»»ä½•æ“ä½œ

:::

| ä¸»æœºå | MasterèŠ‚ç‚¹ | NodeèŠ‚ç‚¹ | EtcdèŠ‚ç‚¹ | å…¶ä»–èŠ‚ç‚¹        | å†…å­˜ | CPU  | é™æ€IP         |
| ------ | ---------- | -------- | -------- | --------------- | ---- | ---- | -------------- |
| node0  | âœ”          | âœ”        | âœ”        | Ansibleä¸»æ§èŠ‚ç‚¹ | 4G   | 2æ ¸  | 192.168.48.128 |
| node1  | âœ”          | âœ”        | âœ”        |                 | 4G   | 2æ ¸  | 192.168.48.134 |
| node2  |            | âœ”        | âœ”        |                 | 4G   | 2æ ¸  | 192.168.48.135 |

**ï¼ˆ2ï¼‰ç‰ˆæœ¬è¯´æ˜**

| åç§°       |         ç‰ˆæœ¬ | å¤‡æ³¨                                       |
| ---------- | -----------: | ------------------------------------------ |
| OS         | `Centos 7.9` | æ‰€ä½¿ç”¨é•œåƒä¸º`CentOS-7-x86_64-DVD-1708.iso` |
| kubespray  |    `v2.19.0` |                                            |
| Kubernetes |    `v1.23.7` | `kubespray v2.19.0`é»˜è®¤å®‰è£…ç‰ˆæœ¬            |

**ï¼ˆ3ï¼‰ç§‘å­¦ä¸Šç½‘**

åœ¨éƒ¨ç½²è¿‡ç¨‹ä¸­éœ€è¦å»æµ·å¤–ä¸‹è½½é•œåƒï¼Œéœ€è¦ä¸»æœºèƒ½å¤Ÿç§‘å­¦ä¸Šç½‘ï¼ˆç›´è¿æˆ–è€…é€šè¿‡`HTTP_PROXY`æ–¹å¼ï¼‰

**ï¼ˆ4ï¼‰æœ€ä½é…ç½®**

æ”¯æŒä¸»æµç³»ç»Ÿï¼Œå†…å­˜æœ€ä½2Gï¼ŒCPUæœ€ä½2æ ¸ï¼Œç£ç›˜30Gä»¥ä¸Š

### ç³»ç»Ÿåˆå§‹åŒ–

å‚è€ƒï¼šã€æ‰‹åŠ¨éƒ¨ç½²-ç³»ç»Ÿåˆå§‹åŒ–ã€‘ç« èŠ‚

### é…ç½®Ansibleä¸»æ§èŠ‚ç‚¹

Ansibleä¸»æ§èŠ‚ç‚¹éƒ¨ç½²åœ¨å“ªé‡Œéƒ½å¯ä»¥ï¼Œåªè¦èƒ½æ§åˆ¶K8s NodeèŠ‚ç‚¹å³å¯

```bash
# ç”Ÿæˆkeygenï¼ˆæ‰§è¡Œssh-keygenï¼Œä¸€è·¯å›è½¦ä¸‹å»ï¼‰
[root@localhost ~]# ssh-keygen

# é…ç½®SSHå…å¯†ç™»å½•
[root@localhost ~]# ssh-copy-id root@192.168.48.128
[root@localhost ~]# ssh-copy-id root@192.168.48.134
[root@localhost ~]# ssh-copy-id root@192.168.48.135

# éªŒè¯å…å¯†ç™»å½•
[root@localhost ~]# ssh root@192.168.48.128  "hostname"
[root@localhost ~]# ssh root@192.168.48.134  "hostname"
[root@localhost ~]# ssh root@192.168.48.135  "hostname"

# å®‰è£…åŸºç¡€è½¯ä»¶
[root@localhost ~]# yum install epel-release python3 git wget -y
[root@localhost ~]# python3 --version
Python 3.6.8

# å‡çº§pipåˆ°æœ€æ–°ç‰ˆ(å¯é€‰,æ¨è)
[root@localhost ~]# pip3 install --upgrade pip -i https://mirrors.aliyun.com/pypi/simple

# ä¸‹è½½kubesprayæºç 
# è‹¥å› ç½‘ç»œä¸‹è½½å¤±è´¥ï¼Œå¯ä»¥ä½¿ç”¨æˆ‘ä»¬å‡†å¤‡å¥½çš„ä»£ç†ï¼ˆç§‘å­¦ä¸Šç½‘ï¼‰ï¼Œwget -cåé¢æ·»åŠ  -e "http_proxy=http://192.168.5.103:7890"
[root@localhost ~]# wget -c https://github.com/kubernetes-sigs/kubespray/archive/v2.19.0.tar.gz 
[root@localhost ~]# tar zxf v2.19.0.tar.gz && cd kubespray-2.19.0

# å®‰è£…Pythonä¾èµ–ï¼ˆå› ä¸ºæˆ‘ä»¬æ˜¯Python 3.6.8ï¼Œæ‰€ä»¥è¿™é‡Œè¦ä½¿ç”¨requirements-2.11.txtï¼Œè¯¦ç»†ä¿¡æ¯å‚è€ƒGitHubï¼‰
[root@localhost kubespray-2.19.0]# pip3 install -r requirements-2.11.txt -i https://mirrors.aliyun.com/pypi/simple

# ç”Ÿæˆé¡¹ç›®é…ç½®
[root@localhost kubespray-2.19.0]# cp -rpf inventory/sample inventory/mycluster

# ä½¿ç”¨çœŸå®çš„hostnameï¼ˆå¦åˆ™ä¼šè‡ªåŠ¨æŠŠä½ çš„hostnameæ”¹æˆnode1/node2...è¿™ç§å“¦ï¼‰
[root@localhost kubespray-2.19.0]# export USE_REAL_HOSTNAME=true

# æŒ‡å®šé…ç½®æ–‡ä»¶ä½ç½®
[root@localhost kubespray-2.19.0]# export CONFIG_FILE=inventory/mycluster/hosts.yaml

# å®šä¹‰ipåˆ—è¡¨ï¼ˆä½ çš„æœåŠ¡å™¨å†…ç½‘ipåœ°å€åˆ—è¡¨ï¼Œ3å°åŠä»¥ä¸Šï¼Œå‰ä¸¤å°é»˜è®¤ä¸ºmasterèŠ‚ç‚¹ï¼‰
[root@localhost kubespray-2.19.0]# declare -a IPS=(
  192.168.48.128
  192.168.48.134
  192.168.48.135
)

# ç”Ÿæˆé…ç½®æ–‡ä»¶
[root@localhost kubespray-2.19.0]# python3 contrib/inventory_builder/inventory.py ${IPS[@]}
DEBUG: Adding group all
DEBUG: Adding group kube-master
DEBUG: Adding group kube-node
DEBUG: Adding group etcd
DEBUG: Adding group k8s-cluster
DEBUG: Adding group calico-rr
DEBUG: adding host node0 to group all
DEBUG: adding host node1 to group all
DEBUG: adding host node2 to group all
DEBUG: adding host node0 to group etcd
DEBUG: adding host node1 to group etcd
DEBUG: adding host node2 to group etcd
DEBUG: adding host node0 to group kube-master
DEBUG: adding host node1 to group kube-master
DEBUG: adding host node0 to group kube-node
DEBUG: adding host node1 to group kube-node
DEBUG: adding host node2 to group kube-node
```

### èŠ‚ç‚¹ä¸ªæ€§åŒ–é…ç½®

```bash
# å®šåˆ¶åŒ–é…ç½®æ–‡ä»¶
# 1. èŠ‚ç‚¹ç»„ç»‡é…ç½®ï¼ˆè¿™é‡Œå¯ä»¥è°ƒæ•´æ¯ä¸ªèŠ‚ç‚¹çš„è§’è‰²ï¼‰
[root@localhost kubespray-2.19.0]# cat inventory/mycluster/hosts.yaml
all:
  hosts:
    node0:
      ansible_host: 192.168.48.128
      ip: 192.168.48.128
      access_ip: 192.168.48.128
    node1:
      ansible_host: 192.168.48.134
      ip: 192.168.48.134
      access_ip: 192.168.48.134
    node2:
      ansible_host: 192.168.48.135
      ip: 192.168.48.135
      access_ip: 192.168.48.135
  children:
    kube_control_plane:
      hosts:
        node0:
        node1:
    kube_node:
      hosts:
        node0:
        node1:
        node2:
    etcd:
      hosts:
        node0:
        node1:
        node2:
    k8s_cluster:
      children:
        kube_control_plane:
        kube_node:
    calico_rr:
      hosts: {}
      
# 2. containerdé…ç½®ï¼ˆè‡ªv2.18.0å¼€å§‹é»˜è®¤ä½¿ç”¨containerdä½œä¸ºå®¹å™¨è¿è¡Œæ—¶ï¼‰
[root@localhost kubespray-2.19.0]# vi inventory/mycluster/group_vars/all/containerd.yml

# 3. å…¨å±€é…ç½®ï¼ˆå¯ä»¥åœ¨è¿™é…ç½®http(s)ä»£ç†å®ç°å¤–ç½‘è®¿é—®ï¼‰
[root@localhost kubespray-2.19.0]# vi inventory/mycluster/group_vars/all/all.yml
http_proxy: "http://192.168.0.100:7890"     # é…ç½®ä»£ç†
https_proxy: "http://192.168.0.100:7890"    # é…ç½®ä»£ç†


# 4. k8sé›†ç¾¤é…ç½®ï¼ˆåŒ…æ‹¬è®¾ç½®å®¹å™¨è¿è¡Œæ—¶ã€svcç½‘æ®µã€podç½‘æ®µç­‰ï¼‰
[root@localhost kubespray-2.19.0]# vi inventory/mycluster/group_vars/k8s_cluster/k8s-cluster.yml
kube_version: v1.23.7                  # K8Sç‰ˆæœ¬ä¿¡æ¯ï¼Œæ— éœ€ä¿®æ”¹ï¼ˆä¹Ÿä¸è¦éšæ„ä¿®æ”¹ï¼‰
kube_service_addresses: 10.200.0.0/16  # é»˜è®¤ä¸º10.233.0.0/18ï¼Œä¿®æ”¹ä¸º10.200.0.0/16
kube_pods_subnet: 10.233.0.0/16        # é»˜è®¤10.233.64.0/18ï¼Œä¿®æ”¹ä¸º10.233.0.0/16
container_manager: containerd	       # é…ç½®å®¹å™¨å¼•æ“ï¼Œä¸ç”¨ä¿®æ”¹

# 5. ä¿®æ”¹etcdéƒ¨ç½²ç±»å‹ä¸ºhostï¼ˆé»˜è®¤æ˜¯dockerï¼‰
[root@localhost kubespray-2.19.0]# vi inventory/mycluster/group_vars/etcd.yml
etcd_deployment_type: host      # é…ç½®etcdéƒ¨ç½²æ–¹å¼ï¼Œé»˜è®¤æ˜¯dockerï¼Œå¦‚æœä½¿ç”¨containerdçš„è¯ï¼Œå¿…é¡»ä½¿ç”¨å®¿ä¸»æœºéƒ¨ç½²ï¼Œå³host

# 6. é™„åŠ ç»„ä»¶ï¼ˆingressã€dashboardç­‰ï¼‰
[root@localhost kubespray-2.19.0]# vi inventory/mycluster/group_vars/k8s_cluster/addons.yml
dashboard_enabled: true			# ä¿®æ”¹ä¸ºtrue
ingress_nginx_enabled: true		# ä¿®æ”¹ä¸ºtrue
metrics_server_enabled: true    # ä¿®æ”¹ä¸ºtrue
```

### éƒ¨ç½²Kubernetesé›†ç¾¤

```bash
# ä½¿ç”¨tmux(å¯é€‰)
[root@localhost kubespray-2.19.0]# yum install tmux -y
[root@localhost kubespray-2.19.0]# tmux new -s k8s_install

# éƒ¨ç½²Kubernetesé›†ç¾¤ï¼ˆè¿™ä¸€æ­¥æ‰§è¡Œçš„æ—¶é—´å¯èƒ½ä¼šå¾ˆé•¿ï¼Œè¿™é‡Œæˆ‘ä½¿ç”¨timeå‘½ä»¤æ¥ç»Ÿè®¡ä¸€ä¸‹æ—¶é•¿ï¼‰
# å¦‚æœæƒ³æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯æˆ–å®šä½å‡ºé”™çš„taskï¼Œå¯ä»¥æ·»åŠ -vvvv
[root@localhost kubespray-2.19.0]# time ansible-playbook -i inventory/mycluster/hosts.yaml  -b cluster.yml

real    29m43.274s
user    8m22.444s
sys     3m51.848s
```

> å®‰è£…æ­¥éª¤æ‰§è¡Œæ—¶é•¿å¹¶ä¸ç¨³å®šï¼Œæ ¹æ®ç³»ç»Ÿé…ç½®ã€ç½‘ç»œè´¨é‡è€Œä¸åŒï¼Œå¿«åˆ™åŠå°æ—¶ï¼Œæ…¢åˆ™å‡ ä¸ªå°æ—¶



### æ£€æŸ¥é›†ç¾¤çŠ¶æ€

```bash
# æŸ¥çœ‹èŠ‚ç‚¹çŠ¶æ€(MasterèŠ‚ç‚¹æ‰§è¡Œ)
[root@localhost kubespray-2.19.0]# kubectl get node
NAME    STATUS   ROLES                  AGE   VERSION
node0   Ready    control-plane,master   15m   v1.23.7
node1   Ready    control-plane,master   14m   v1.23.7
node2   Ready    <none>                 13m   v1.23.7

# æŸ¥çœ‹MasterèŠ‚ç‚¹ç»„ä»¶çŠ¶æ€(MasterèŠ‚ç‚¹æ‰§è¡Œ)
[root@localhost kubespray-2.19.0]# kubectl get cs
Warning: v1 ComponentStatus is deprecated in v1.19+
NAME                 STATUS    MESSAGE                         ERROR
controller-manager   Healthy   ok                              
scheduler            Healthy   ok                              
etcd-2               Healthy   {"health":"true","reason":""}   
etcd-0               Healthy   {"health":"true","reason":""}   
etcd-1               Healthy   {"health":"true","reason":""}   

# æŸ¥çœ‹PodçŠ¶æ€
[root@localhost kubespray-2.19.0]# kubectl get pods -A
NAMESPACE       NAME                                          READY   STATUS    RESTARTS   AGE
ingress-nginx   ingress-nginx-controller-hs8ld                1/1     Running   0          13m
ingress-nginx   ingress-nginx-controller-k6qzm                1/1     Running   0          13m
ingress-nginx   ingress-nginx-controller-kcggb                1/1     Running   0          13m
kube-system     calico-kube-controllers-6dd874f784-wxf8q      1/1     Running   0          13m
kube-system     calico-node-krtfp                             1/1     Running   0          14m
kube-system     calico-node-sn44p                             1/1     Running   0          14m
kube-system     calico-node-vfzzd                             1/1     Running   0          14m
kube-system     coredns-76b4fb4578-5jkmj                      1/1     Running   0          12m
kube-system     coredns-76b4fb4578-75bdd                      1/1     Running   0          13m
kube-system     dns-autoscaler-7979fb6659-5597v               1/1     Running   0          12m
kube-system     kube-apiserver-node0                          1/1     Running   1          16m
kube-system     kube-apiserver-node1                          1/1     Running   1          15m
kube-system     kube-controller-manager-node0                 1/1     Running   1          16m
kube-system     kube-controller-manager-node1                 1/1     Running   1          15m
kube-system     kube-proxy-fh2wf                              1/1     Running   0          14m
kube-system     kube-proxy-znqrr                              1/1     Running   0          14m
kube-system     kube-proxy-znvz6                              1/1     Running   0          14m
kube-system     kube-scheduler-node0                          1/1     Running   1          16m
kube-system     kube-scheduler-node1                          1/1     Running   1          15m
kube-system     kubernetes-dashboard-584bfbb648-6k96s         1/1     Running   0          12m
kube-system     kubernetes-metrics-scraper-5dc755864d-glpwt   1/1     Running   0          12m
kube-system     metrics-server-749474f899-szbn5               1/1     Running   0          12m
kube-system     nginx-proxy-node2                             1/1     Running   0          14m
kube-system     nodelocaldns-cmzbt                            1/1     Running   0          12m
kube-system     nodelocaldns-gkgh9                            1/1     Running   0          12m
kube-system     nodelocaldns-m2zvj                            1/1     Running   0          12m
```

### æ¸…ç†ä»£ç†è®¾ç½®

```bash
# æ¸…ç†Containerd HTTPä»£ç†
[root@localhost ~]# cat /etc/systemd/system/containerd.service.d/http-proxy.conf
[Service]
Environment="HTTP_PROXY=http://192.168.0.100:7890" "HTTPS_PROXY=http://192.168.0.100:7890" "NO_PROXY=192.168.48.128,node0,node0.cluster.local,192.168.48.134,node1,node1.cluster.local,192.168.48.135,node2,node2.cluster.local,127.0.0.1,localhost,10.200.0.0/16,10.233.0.0/16,svc,svc.cluster.local"

[root@localhost ~]# mv /etc/systemd/system/containerd.service.d/http-proxy.conf /etc/systemd/system/containerd.service.d/http-proxy.conf_$(date +"%Y-%m-%d-%H%M%S")
[root@localhost ~]# systemctl daemon-reload
[root@localhost ~]# systemctl restart containerd

# æ¸…ç†Yum HTTPä»£ç†(æŠŠgrepå‡ºæ¥çš„ä»£ç†é…ç½®æ³¨é‡Šæˆ–åˆ é™¤å³å¯)
[root@localhost ~]# grep 7890 -r /etc/yum*
/etc/yum.conf:proxy=http://192.168.0.100:7890
```



### è®¿é—®dashboard

```bash
# åˆ›å»ºservice
[root@localhost ~]# cat > dashboard-svc.yaml <<EOF
apiVersion: v1
kind: Service
metadata:
  namespace: kube-system
  name: dashboard
  labels:
    app: dashboard
spec:
  type: NodePort
  selector:
    k8s-app: kubernetes-dashboard
  ports:
  - name: https
    nodePort: 30000
    port: 443
    targetPort: 8443
EOF

[root@localhost ~]# kubectl apply -f dashboard-svc.yaml

# è®¿é—®dashboard
ä¸ºäº†é›†ç¾¤å®‰å…¨ï¼Œä» 1.7 å¼€å§‹ï¼Œdashboard åªå…è®¸é€šè¿‡ https è®¿é—®ï¼Œæˆ‘ä»¬ä½¿ç”¨nodeportçš„æ–¹å¼æš´éœ²æœåŠ¡ï¼Œå¯ä»¥ä½¿ç”¨ https://NodeIP:NodePort åœ°å€è®¿é—® 
å…³äºè‡ªå®šä¹‰è¯ä¹¦ é»˜è®¤dashboardçš„è¯ä¹¦æ˜¯è‡ªåŠ¨ç”Ÿæˆçš„ï¼Œè‚¯å®šæ˜¯éå®‰å…¨çš„è¯ä¹¦ï¼Œå¦‚æœå¤§å®¶æœ‰åŸŸåå’Œå¯¹åº”çš„å®‰å…¨è¯ä¹¦å¯ä»¥è‡ªå·±æ›¿æ¢æ‰ã€‚ä½¿ç”¨å®‰å…¨çš„åŸŸåæ–¹å¼è®¿é—®dashboardã€‚ 
åœ¨dashboard-all.yamlä¸­å¢åŠ dashboardå¯åŠ¨å‚æ•°ï¼Œå¯ä»¥æŒ‡å®šè¯ä¹¦æ–‡ä»¶ï¼Œå…¶ä¸­è¯ä¹¦æ–‡ä»¶æ˜¯é€šè¿‡secretæ³¨è¿›æ¥çš„ã€‚
- â€“tls-cert-file
- dashboard.cer
- â€“tls-key-file
- dashboard.key

# åˆ›å»ºservice account
[root@localhost ~]# kubectl create sa dashboard-admin -n kube-system

# åˆ›å»ºè§’è‰²ç»‘å®šå…³ç³»
[root@localhost ~]# kubectl create clusterrolebinding dashboard-admin --clusterrole=cluster-admin --serviceaccount=kube-system:dashboard-admin

# æŸ¥çœ‹dashboard-adminçš„secretåå­—
[root@localhost ~]# ADMIN_SECRET=$(kubectl get secrets -n kube-system | grep dashboard-admin | awk '{print $1}')

# æ‰“å°secretçš„token
[root@localhost ~]# kubectl describe secret -n kube-system ${ADMIN_SECRET} | grep -E '^token' | awk '{print $2}'

# æµè§ˆå™¨è®¿é—®
[root@localhost ~]# https://192.168.48.128:30000/
```



### FAQ

**ï¼ˆ1ï¼‰Download file error**

![image-20211229101545405](https://tuchuang-1257805459.cos.accelerate.myqcloud.com/image-20211229101545405.png)

> ä¸‹è½½æ–‡ä»¶å‡ºé”™ï¼Œä»ä»¥ä¸‹æ–¹é¢æ’æŸ¥
>
> * æ£€æŸ¥æœ¬åœ°ç½‘ç»œã€ä»£ç†æœåŠ¡å™¨æ˜¯å¦æ­£å¸¸
> * æ£€æŸ¥é…ç½®æ˜¯å¦å†™é”™
>   * æ¯”å¦‚å°†ä»£ç†æœåŠ¡å™¨çš„`http://`è¯¯å†™æˆäº†`https://`
>   * æ¯”å¦‚å°†ä»£ç†æœåŠ¡å™¨çš„`http://`è¯¯å†™æˆ`http:/`

<br />

**ï¼ˆ2ï¼‰ç»„ä»¶çŠ¶æ€ä¸ºUnhealthy**

`scheduler`å’Œ`controller-manager`ç»„ä»¶çŠ¶æ€ä¸º`Unhealthy`

```bash
# ä¿®å¤Unhealthy(åœ¨æ‰€æœ‰Masterä¸Šæ“ä½œ)
[root@localhost ~]# vi /etc/kubernetes/manifests/kube-controller-manager.yaml
    # - --port=0    # å°†è¿™ä¸€è¡Œæ³¨é‡Šæ‰
[root@localhost ~]# vi /etc/kubernetes/manifests/kube-scheduler.yaml
    # - --port=0    # å°†è¿™ä¸€è¡Œæ³¨é‡Šæ‰

# é‡å¯kubelet
[root@localhost ~]# systemctl restart kubelet
```

<br />

**ï¼ˆ3ï¼‰SSHè¶…æ—¶**

**é”™è¯¯æè¿°**

`Ansible`è¿æ¥æŠ¥é”™ä¿¡æ¯ï¼š`Timeout (12s) waiting for privilege escalation prompt`

æ‰‹åŠ¨è°ƒç”¨`ssh`å‘½ä»¤åˆ™ä¼šä¸€ç›´å¡ç€

**è§£å†³åŠæ³•**

æ–¹æ³•1ï¼šå…³é—­SSHåå‘è§£æï¼ˆæ¨èä½¿ç”¨ï¼‰

```bash
[root@node0 kubespray-2.19.0]# vi /etc/ssh/sshd_config 
UseDNS no

[root@node0 ~]# systemctl restart sshd.service
```

æ–¹æ³•2ï¼šè°ƒæ•´Ansible SSHè¶…æ—¶æ—¶é—´

```bash
# è°ƒå¤§è¶…æ—¶æ—¶é—´
[root@node0 kubespray-2.19.0]# vim ansible.cfg 
[ssh_connection]
# ...
timeout = 300			# è®¾ç½®è¶…æ—¶æ—¶é—´300ç§’
gather_timeout = 300    # è®¾ç½®è¶…æ—¶æ—¶é—´300ç§’
```

## 